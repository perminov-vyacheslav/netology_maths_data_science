# -*- coding: utf-8 -*-
"""Итоговый проект по курсу «Математика для Data Science».ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VBiWu93NWihmFWoAMZFVzVQTxE0ToGFU
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
import sympy as sp

from scipy.optimize import differential_evolution
from scipy.optimize import minimize
from scipy.stats import norm
from sklearn.metrics.pairwise import cosine_similarity
# %matplotlib inline

"""Задание 1"""

# Определяем символьную переменную x
x = sp.symbols('x')

# Определяем функцию f(x)
f = sp.tan(sp.sin(x) + sp.cos(2*x + 3))**2

# Вычисляем производную функции по переменной x
derivative = sp.diff(f, x)

# Вычисляем значение производной в точке x = 1
derivative_1 = derivative.subs(x, 1)

# Выводим результат
print("Производная функции в точке x=1 равна:")
print(derivative_1)

"""Задание 2"""

# Исходный объект
A = np.array([
    [-100, -100, 1],
    [0, 100, 1],
    [100, -100, 1],
    [-100, -100, 1]
])

# Матрица масштабирования
scale_matrix = np.array([
    [0.5, 0, 0],
    [0, 1.2, 0],
    [0, 0, 1]
])

# Матрица смещения
translate_matrix = np.array([
    [1, 0, 200],
    [0, 1, 300],
    [0, 0, 1]
])

# Применяем матрицы трансформаций к объекту A
transformed_A = np.dot(scale_matrix, A.T).T
transformed_A = np.dot(translate_matrix, transformed_A.T).T

x = transformed_A[:, 0]
y = transformed_A[:, 1]

# Отображение нового положения объекта
plt.plot(x, y)
plt.ylim([0, 500])
plt.xlim([0, 400])
plt.gca().set_aspect('equal', adjustable='box')
plt.show()

"""Задание 3"""

m = np.array([[1, 4],
              [1, 1]])

print(m)

# Находим собственные значения и собственные векторы
values, vectors = np.linalg.eig(m)

print("\nСобственные значения:")
print(values)

print("\nСобственные векторы:")
print(vectors)

"""Задание 4"""

x = np.array([0., 0.26315789, 0.52631579, 0.78947368, 1.05263158,
              1.31578947, 1.57894737, 1.84210526, 2.10526316, 2.36842105,
              2.63157895, 2.89473684, 3.15789474, 3.42105263, 3.68421053,
              3.94736842, 4.21052632, 4.47368421, 4.73684211, 5.])

fx = np.array([ 0., -12.01819092, -18.90968634, -17.68786571,
                -8.7529108 ,   4.27524517,  16.06801336,  21.81250213,
                19.22059845,   9.48411207,  -3.22273056, -13.48576488,
               -16.91096359, -11.95866834,  -0.58630088,  12.56873816,
                22.12489421,  24.20292139,  18.04522521,   6.33211092])

def f(x, a, b):
    return np.exp(a) * np.sin(b * x) + x

def error(params):
    return np.sum(np.abs(fx - f(x, params[0], params[1])))

res = minimize(error, x0=[0, 0], method='Nelder-Mead')

a_opt, b_opt = res.x
print("Оптимальные параметры a и b:", a_opt, b_opt)

"""Задание 5"""

raitings = np.array([[ 4,  4,  9,  4,  1,  6, 10,  7,  9,  6,  9,  2,  8,  6,  6],
                     [ 9,  2,  5, 10,  7,  8, 10,  5,  6,  2,  1,  6,  8,  9,  7],
                     [ 1,  6,  8,  8,  4,  9,  3,  8, 10,  5,  2,  6,  8,  1,  6],
                     [ 6,  1,  9,  7,  7,  9,  2,  3,  5,  1,  6,  6,  3,  2,  7],
                     [ 3,  7,  3,  5,  7,  9,  9,  6,  2,  9,  1,  2,  8, 10,  6],
                     [ 8,  3,  7,  3,  8,  6,  1,  8,  8,  6,  1,  9,  4, 10,  1],
                     [ 9,  8,  4,  8,  8, 10,  6,  1,  1,  2,  9,  5,  2,  7,  2],
                     [ 4,  1,  6,  4,  3, 10,  4,  4,  2,  8,  7,  9,  3,  8,  3],
                     [ 2,  7,  7,  6, 10,  6,  8,  9,  8,  6, 10,  1,  7, 10,  4],
                     [ 5, 10,  8,  8,  9,  7,  2,  9,  9, 10,  8,  8,  8,  6, 10]])
for i in range(len(raitings)):
    similarities = cosine_similarity([raitings[i]], raitings)[0]
    most_similar_user = np.argsort(similarities)[-2]
    print(f"Наиболее похожий пользователь на пользователя {i+1} - пользователь {most_similar_user+1}")